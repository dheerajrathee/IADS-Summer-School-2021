{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradientBoostingRegressor-IADS2019.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dheerajrathee/IADS_SummerSchool_2019/blob/master/GradientBoostingRegressor_IADS2019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPBHwNGVpbPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')\n",
        "# %cd /gdrive/My Drive/IADS-2019-Tree-Codes\n",
        "# !pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev6gbXGYfLfp",
        "colab_type": "text"
      },
      "source": [
        "# **Gradient Boosting for Regression**\n",
        "### 1. Boston House Price dataset\n",
        "### 2. House Sales in King County, USA\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06YtVCBqkbf5",
        "colab_type": "text"
      },
      "source": [
        "# 1. Boston House Price dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jWOszUoksPX",
        "colab_type": "text"
      },
      "source": [
        "## Dataset for Regression\n",
        "\n",
        "\n",
        "\n",
        "> **Dataset:**  [Boston house-price](https://scikit-learn.org/stable/datasets/index.html#boston-dataset)\n",
        "\n",
        "\n",
        "\n",
        "*   **Number of Instances:** \n",
        "    *   \t506\n",
        "*   **Number of Attributes:**\n",
        "    *   13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
        "\n",
        "*   **Attribute Information:**\n",
        "    *   CRIM per capita crime rate by town\n",
        "    *   ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "    *   INDUS proportion of non-retail business acres per town\n",
        "    *   CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "    *   NOX nitric oxides concentration (parts per 10 million)\n",
        "    *   RM average number of rooms per dwelling\n",
        "    *   AGE proportion of owner-occupied units built prior to 1940\n",
        "    *   DIS weighted distances to five Boston employment centres\n",
        "    *   RAD index of accessibility to radial highways\n",
        "    *   TAX full-value property-tax rate per \\$10,000\n",
        "    *   PTRATIO pupil-teacher ratio by town\n",
        "    *   B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "    *   LSTAT \\% lower status of the population\n",
        "    *   MEDV Median value of owner-occupied homes in \\$1000â€™s\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhWxdDXGfa_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add liberaries \n",
        "from sklearn import datasets  # DATA\n",
        "from sklearn.model_selection import train_test_split # to Split Train-Test data\n",
        "from sklearn import ensemble # To get Gradient Boosting regressor \n",
        "from sklearn import metrics # To generate evaluation metrices\n",
        "from sklearn.model_selection import cross_val_predict # To estimate CV predicted outputs\n",
        "from sklearn.model_selection import cross_val_score # To estimate CV score\n",
        "\n",
        "\n",
        "from sklearn.tree import export_graphviz # exporting the tree structure as dot file\n",
        "from pydotplus.graphviz import graph_from_dot_data # export png image from dot file\n",
        "from IPython.display import Image, SVG # Show the image within colab notebook\n",
        "from graphviz import Source\n",
        "import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "import pandas as pd # for basic data exploration and manipulations \n",
        "import numpy as np # Numpy for data manipulations\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV # get gridsearch with cross validation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVvhtZmzgZt6",
        "colab_type": "text"
      },
      "source": [
        "### 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ouc794ShFCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data and see meta info\n",
        "boston = datasets.load_boston()\n",
        "dir(boston)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn5ALWzlg5v_",
        "colab_type": "text"
      },
      "source": [
        "### 2. Explore Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6uvmutxjMWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print type and shape of data\n",
        "print(type(boston.data))\n",
        "print(type(boston.target))\n",
        "\n",
        "print(boston.data.shape)\n",
        "print(boston.target.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWK8ExaZieM9",
        "colab_type": "text"
      },
      "source": [
        "### 3. Create Panda Dataframe and do data manipulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8GXIW8bhdyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfReg = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "dfReg.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAUu50i_hk8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add target data to the panda dataframe\n",
        "dfReg['target'] = boston.target\n",
        "dfReg.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92JNHnFqiwq-",
        "colab_type": "text"
      },
      "source": [
        "### 4. Split the data for Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac89rgVlkDHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dfReg.drop(['target'],axis='columns'),boston.target,test_size=0.1,random_state=123)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmFoeacki95Y",
        "colab_type": "text"
      },
      "source": [
        "### 5. Initialise a Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmsuBza6lba-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbRegressor = ensemble.GradientBoostingRegressor(loss='ls', learning_rate=0.1,\n",
        "                                                   n_estimators=100, subsample=1.0, \n",
        "                                                   criterion='friedman_mse', \n",
        "                                                   min_samples_split=2, min_samples_leaf=1, \n",
        "                                                   min_weight_fraction_leaf=0.0, max_depth=3, \n",
        "                                                   min_impurity_decrease=0.0, min_impurity_split=None, \n",
        "                                                   init=None, random_state=123, max_features=None, \n",
        "                                                   alpha=0.9, verbose=0, max_leaf_nodes=None, \n",
        "                                                   warm_start=False, presort='auto', \n",
        "                                                   validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY8sN-mo4Ztn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> ***Let's dig into*** **[tree.GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LZ65_P4CuiZ",
        "colab_type": "text"
      },
      "source": [
        "### 6. Model Evaluation on Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbphECGHXQTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CV_predicted = cross_val_predict(gbRegressor, X_train, y_train, cv=10) # CV prediction on Train data\n",
        "r2_score_cv = cross_val_score(gbRegressor, X_train, y_train, cv=10).mean() # CV model score on Train data\n",
        "print (\"Crossvalidation Coefficient of determination on training set :\",r2_score_cv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAaHHAHL7ZLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot measured values vs predicted values Training Data\n",
        "plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.scatter(y_train, CV_predicted, edgecolors=(0, 0, 0))\n",
        "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=4)\n",
        "plt.xlabel('Measured')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Measured vs Predicted Values for Training Data (10x CV)')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FHoUgZGjHSo",
        "colab_type": "text"
      },
      "source": [
        "### 7. Let's fit the GB model on Training data and perform prediction with the Test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9afkTHSwlh-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbRegressor_model = gbRegressor.fit(X_train,y_train)\n",
        "\n",
        "y_predicted = gbRegressor_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcorWrwVjlr_",
        "colab_type": "text"
      },
      "source": [
        "### 8. Model Evaluation on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgGWc9H3lpbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r2_score = gbRegressor.score(X_test,y_test) #R2 Score\n",
        "print (\"Coefficient of determination on test set: \",r2_score)\n",
        "\n",
        "mse_score = metrics.mean_squared_error(y_test, y_predicted) #Mean Squared Error\n",
        "print (\"\\nMean Squared Error on test set :\",mse_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdqlUoPt7y1s",
        "colab_type": "text"
      },
      "source": [
        "### 9. Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKgULWpZ76-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot measured values vs predicted values\n",
        "plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.scatter(y_test, y_predicted, edgecolors=(0, 0, 0))\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=4)\n",
        "plt.xlabel('Measured')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Measured vs Predicted Values for Test Data')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta8v_fll763N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot a one-to-one comparison of measured values vs predicted values\n",
        "plt.figure(num=None, figsize=(25, 4), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.plot(y_predicted, 'gd-', label='GradientBoostingRegressor')\n",
        "plt.plot(y_test, 'r*-', label='Actual values')\n",
        "plt.tick_params(axis='x', which='both', bottom=False, top=False,\n",
        "                labelbottom=False)\n",
        "plt.ylabel('Target values')\n",
        "plt.xlabel('Training samples')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.title('Comparison of individual sample predictions')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Az1X5VA76dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot feature importance\n",
        "feature_importance = gbRegressor_model.feature_importances_\n",
        "# make importances relative to max importance\n",
        "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "pos = range(X_train.shape[1]);\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, boston.feature_names[sorted_idx])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.title('Variable Importance')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_2WjHs99Guu",
        "colab_type": "text"
      },
      "source": [
        "### 10. Let's do Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErB0_KML9RFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#provide GB hyperparameters\n",
        "gb_hyperparameters = {\n",
        "    \"n_estimators\": [100, 300, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [1, 3, 5],\n",
        "#     'loss' : ['ls', 'lad', 'huber', 'quantile'],\n",
        "}\n",
        "\n",
        "nfolds = 10 #number of folds for CV\n",
        "gbRegressor = ensemble.GradientBoostingRegressor(random_state=123) #initialise GB classifier\n",
        "\n",
        "# create Grid search object\n",
        "gs_gb_rgr = GridSearchCV(gbRegressor, gb_hyperparameters, \n",
        "                          n_jobs=10, cv=nfolds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjHW0ac89RCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gs_gb_rgr.fit(X_train, y_train) #fit the grid search object"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsjTgPJe9Q0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(gs_gb_rgr.best_score_)\n",
        "print(gs_gb_rgr.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taftUzsRTkW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_parameters_gs = gs_gb_rgr.best_params_ #get the best parameters based on 10x CV grid search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1_iAAMjTsxj",
        "colab_type": "text"
      },
      "source": [
        "### 11. Re-Initialise a Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLSAUWjVTy7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbRegressor_best = ensemble.GradientBoostingRegressor(**best_parameters_gs) #intialise GB classifier with best set of parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYbETqljT_u3",
        "colab_type": "text"
      },
      "source": [
        "### 12. Model Re-evaluation on Train data with best Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE3oZq9_T_Yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform 10 fold cross validation and plot the CM\n",
        "CV_predicted = cross_val_predict(gbRegressor_best, X_train, y_train, cv=10) #CV predicted values (training data)\n",
        "CV_score = cross_val_score(gbRegressor_best, X_train, y_train, cv=10) #CV model score (training data)\n",
        "\n",
        "print(\"Cross validation Score with best parameters on train data: \",CV_score.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Uo5Yo-ULpU",
        "colab_type": "text"
      },
      "source": [
        "### 13. Model Re-evaluation on Test data with best Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kG2H0CgT-x9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbRegressor_best_mdl= gbRegressor_best.fit(X_train, y_train) #fit the best GB classifier with training data\n",
        "\n",
        "y_predicted = gbRegressor_best_mdl.predict(X_test) #Predict the outcomes with best GB classifier for test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU-dGTZyUhMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mdl_score = gbRegressor_best_mdl.score(X_test,y_test) #model score (test data)\n",
        "print (\"Model Score with best parameters on test data:\",mdl_score)\n",
        "\n",
        "mse_score = metrics.mean_squared_error(y_test, y_predicted) #Mean Squared Error\n",
        "print (\"\\nMean Squared Error with best parameters on test set :\",mse_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nlfrtaqAtAIq"
      },
      "source": [
        "# 1. House Sales in King County, USA dataset\n",
        "[see description here](https://www.kaggle.com/harlfoxem/housesalesprediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zSDLFCqttv9s"
      },
      "source": [
        "### 1. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yieErMHJ39Q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data from local drive\n",
        "housePriceData = pd.read_csv('kc_house_data.csv')\n",
        "housePriceData.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fjBdBqWft6De"
      },
      "source": [
        "### 2. Explore Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auIFo7VxbTuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housePriceData.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAKtHY0ibc-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housePriceData = housePriceData.drop(['id', 'date'], axis=1) #remove 'id' and 'date' variables\n",
        "housePriceData.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78N64_4ubpMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housePriceData.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpFGm65ncHoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housePriceData.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ct3AHytgt6Dj"
      },
      "source": [
        "### 3. Split the data for Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNwVdWTUcOCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = housePriceData['price'] #get the labels as targets and convert to numpy array\n",
        "np.array(target, dtype=pd.Series)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBgk_IVbdRcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(housePriceData.drop(['price'],axis='columns'), target, test_size=0.2,random_state=123)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LW1dBI-3uL1Z"
      },
      "source": [
        "### 4. Let's do Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX6_TwZrdat3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#provide GB hyperparameters\n",
        "gb_hyperparameters = {\n",
        "    \"n_estimators\": [100, 300],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'max_depth': [1, 3],\n",
        "#     'loss' : ['ls', 'lad', 'huber', 'quantile'],\n",
        "}\n",
        "\n",
        "nfolds = 10 #number of folds for CV\n",
        "gbRegressor = ensemble.GradientBoostingRegressor(random_state=123) #initialise GB classifier\n",
        "\n",
        "# create Grid search object\n",
        "gs_gb_rgr = GridSearchCV(gbRegressor, gb_hyperparameters, cv=nfolds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WnwttxJxd2FM",
        "colab": {}
      },
      "source": [
        "gs_gb_rgr.fit(X_train, y_train) #fit the grid search object"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GkJkJ7Ndd2FX",
        "colab": {}
      },
      "source": [
        "print(gs_gb_rgr.best_score_)\n",
        "print(gs_gb_rgr.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6GquLqo9d2Fb",
        "colab": {}
      },
      "source": [
        "best_parameters_gs = gs_gb_rgr.best_params_ #get the best parameters based on 10x CV grid search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qJ0N3gZjuL1a"
      },
      "source": [
        "### 5. Initialise a Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bt-7aqURd9xP",
        "colab": {}
      },
      "source": [
        "gbRegressor_best = ensemble.GradientBoostingRegressor(**best_parameters_gs, random_state=123) #intialise GB classifier with best set of parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JC0XM_dkd9xS"
      },
      "source": [
        "### 6. Model Re-evaluation on Train data with best Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gd3qVIxLd9xS",
        "colab": {}
      },
      "source": [
        "#perform 10 fold cross validation and plot the CM\n",
        "CV_predicted = cross_val_predict(gbRegressor_best, X_train, y_train, cv=10) #CV predicted values (training data)\n",
        "CV_score = cross_val_score(gbRegressor_best, X_train, y_train, cv=10) #CV model score (training data)\n",
        "\n",
        "print(\"Cross validation Score with best parameters on train data: \",CV_score.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dLGouWqCiHUc",
        "colab": {}
      },
      "source": [
        "# Plot measured values vs predicted values Training Data\n",
        "plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.scatter(y_train, CV_predicted, edgecolors=(0, 0, 0))\n",
        "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=4)\n",
        "plt.xlabel('Measured')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Measured vs Predicted Values for Training Data (10x CV)')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V-FLb1ebd9xV"
      },
      "source": [
        "### 7. Model Re-evaluation on Test data with best Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RGnu-SWld9xW",
        "colab": {}
      },
      "source": [
        "gbRegressor_best_mdl= gbRegressor_best.fit(X_train, y_train) #fit the best GB classifier with training data\n",
        "\n",
        "y_predicted = gbRegressor_best_mdl.predict(X_test) #Predict the outcomes with best GB classifier for test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Br7QSLsNd9xZ",
        "colab": {}
      },
      "source": [
        "mdl_score = gbRegressor_best_mdl.score(X_test,y_test) #model score (test data)\n",
        "print (\"Model Score with best parameters on test data:\",mdl_score)\n",
        "\n",
        "model_error = 1- mdl_score\n",
        "print (\"\\nModel Error with best parameters on test set :\",model_error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DvhKdMACiz38"
      },
      "source": [
        "### 8. Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CQ0UQCO6iz3-",
        "colab": {}
      },
      "source": [
        "# Plot measured values vs predicted values\n",
        "plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.scatter(y_test, y_predicted, edgecolors=(0, 0, 0))\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=4)\n",
        "plt.xlabel('Measured')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Measured vs Predicted Values for Test Data')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bOgIY_UOiz4E",
        "colab": {}
      },
      "source": [
        "# Plot feature importance\n",
        "feature_importance = gbRegressor_best_mdl.feature_importances_\n",
        "# make importances relative to max importance\n",
        "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "pos = range(X_train.shape[1]);\n",
        "\n",
        "array_features = np.asarray(list(housePriceData))\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, array_features[sorted_idx])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.title('Variable Importance')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPviyaxe6ha0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}